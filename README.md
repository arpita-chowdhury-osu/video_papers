# video_papers

# ICLR 2026
| Paper Name    | Short Description | Tag |
| -------- | ------- | ------|
|[DSA: Efficient Inference For Video Generation Models via Distributed Sparse Attention](https://openreview.net/forum?id=1ZmdfDzGE1)|proposed distributed sparse attention (DSA) for DiT-based video generation models|System|
|[Multi-Object System Identification from Videos](https://openreview.net/forum?id=0ylAe3Orfy)|This paper introduces MOSIV, a new framework created to solve the problem of identifying the physical properties of multiple interacting objects simultaneously from a video. MOSIV works by using a differentiable simulator. It directly optimizes the specific, continuous material parameters for each object by trying to match the geometry observed in the video.|Nerf|
|[WAVEPOLYP: VIDEO POLYP SEGMENTATION VIA HI-ERARCHICAL WAVELET-BASED FEATURE AGGREGA-TION AND INTER-FRAME DIVERGENCE PERCEPTION](https://openreview.net/forum?id=Sm3Y0TMnDv)|This paper presents a carefully engineered framework for video polyp segmentation, combining frequency-domain feature aggregation with explicit modeling of inter-frame divergence.|Medical, Segmentation|
|[TTOM: TEST-TIME OPTIMIZATION AND MEMORIZA-TION FOR COMPOSITIONAL VIDEO GENERATION](https://arxiv.org/pdf/2510.07940)|This paper introduces TTOM, a training-free framework that enhances compositional text-to-video (T2V) generation through test-time optimization (TTO) and a parametric memory mechanism.|Generation, Test-time optimization|
|[WorldTree: Towards 4D Dynamic Worlds from Monocular Video using Tree-Chains](https://openreview.net/forum?id=mVo6cyFR6C)|reconstruct a high-quality 4D (3D + time) dynamic scene from a single monocular video(2D video)|Generation,3DGS|
|[VideoNSA: Native Sparse Attention Scales Video Understanding](https://arxiv.org/pdf/2510.02295)||Efficiency|
|[MatAnyone 2: Scaling Video Matting via a Learned Quality Evaluator](https://arxiv.org/pdf/2512.11782)||Matting(Segmentation)|
|[STREAMINGVLM: REAL-TIME UNDERSTANDING FOR INFINITE VIDEO STREAMS](https://arxiv.org/pdf/2510.09608)|How to train on short videos and still enable the model to reason over very long streams|Efficiency, Understanding, Long Video|
|[REWATCH-R1: BOOSTING COMPLEX VIDEO REASON-ING IN LARGE VISION-LANGUAGE MODELS THROUGHAGENTIC DATA SYNTHESIS](https://arxiv.org/pdf/2509.23652)||Reasoning, RL, Agent|
|[DELIVR: DIFFERENTIAL SPATIOTEMPORAL LIE BIAS FOR EFFICIENT VIDEO DERAINING](https://arxiv.org/pdf/2509.21719)||Deraining|
|[Privacy Beyond Pixels: Latent Anonymization for Privacy-Preserving Video Understanding](http://arxiv.org/pdf/2511.08666)||privacy, fm Adaptation|
|[DeAltHDR: Learning HDR Video Reconstruction from Degraded Alternating Exposure Sequences](https://openreview.net/forum?id=buzIPnGxA8)|Aim to make HDR video reconstruction work reliably in real-world conditions where input frames are noisy, blurry, and captured with alternating exposures.|HDR video|
|[PPLLaVA: Varied Video Sequence Understanding With Prompt Guidance](https://arxiv.org/pdf/2411.02327)||Efficiency,RL, Understanding, Long-Video|
|[Video Scene Segmentation with Genre and Duration Signals](https://openreview.net/forum?id=c8r3lzyVTS)||Clip Segmentation|
|[Streaming Drag-Oriented Interactive Video Manipulation: Drag Anything, Anytime!](https://arxiv.org/pdf/2510.03550)||Controlled Generation|
|[Anchor Frame Bridging for Coherent First-Last Frame Video Generation](https://openreview.net/pdf?id=isNjWnVsUR)|Given first and last frame, generate better intermediate frames|Video Frame Interpolation|
|[UrbanVerse: Scaling Urban Simulation by Watching City-Tour Videos](https://arxiv.org/pdf/2510.15018)|They build a real-to-simulation system that turns city-tour videos into realistic urban simulators for scalable robot navigation training.|physics-grounded scene construction|
|[ViPRA: Video Prediction for Robot Actions]|(https://arxiv.org/pdf/2511.07732)||
|[MIMIC: Mask-Injected Manipulation Video Generation with Interaction Control](https://openreview.net/forum?id=COrUdVuInH)|||
